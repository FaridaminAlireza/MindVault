"""
Mapping coordinates into an orthonormal basis

if {e‚ÇÅ,‚Ä¶,e‚Çñ} is an orthonormal basis, the coordinates of a vector v
in that basis are simply the dot products c·µ¢ = v¬∑e·µ¢. 
If you start with some other basis, use Gram‚ÄìSchmidt to make it orthonormal first.

---
1) Problem setup (example)

Work in ‚Ñù¬≥. Start with a non-orthonormal basis of a 2-dimensional subspace:
u‚ÇÅ = (1, 1, 0)
u‚ÇÇ = (1, 0, 1)
and take the input vector
v = (2, 1, 1)

Goal: find coordinates of v in an orthonormal basis for span{u‚ÇÅ, u‚ÇÇ}.

-------------------------------------------------------------------------------------
2) Orthonormalize the basis (Gram‚ÄìSchmidt)
-------------------------------------------------------------------------------------
Step 2.1 ‚Äî first orthonormal vector e‚ÇÅ:
‚Äñu‚ÇÅ‚Äñ = ‚àö2
e‚ÇÅ = (1/‚àö2, 1/‚àö2, 0)

Step 2.2 ‚Äî make u‚ÇÇ orthogonal to e‚ÇÅ:
proj‚Çë‚ÇÅ(u‚ÇÇ) = (u‚ÇÇ¬∑e‚ÇÅ)e‚ÇÅ = (1/‚àö2)e‚ÇÅ
v‚ÇÇ = u‚ÇÇ - proj‚Çë‚ÇÅ(u‚ÇÇ) = (1,0,1) - (¬Ω,¬Ω,0) = (¬Ω, -¬Ω, 1)

Step 2.3 ‚Äî normalize v‚ÇÇ to get e‚ÇÇ:
‚Äñv‚ÇÇ‚Äñ = ‚àö(3/2) = ‚àö6 / 2
e‚ÇÇ = (1/‚àö6, -1/‚àö6, 2/‚àö6)

Now {e‚ÇÅ, e‚ÇÇ} is an orthonormal basis.

-------------------------------------------------------------------------------------
3) Compute coordinates of v in the orthonormal basis
-------------------------------------------------------------------------------------
c‚ÇÅ = v¬∑e‚ÇÅ = 3/‚àö2
c‚ÇÇ = v¬∑e‚ÇÇ = 3/‚àö6

Coordinates of v relative to {e‚ÇÅ, e‚ÇÇ}:
[v]_(e‚ÇÅ,e‚ÇÇ) = [3/‚àö2, 3/‚àö6]^T

Reconstruction check: (3/‚àö2)e‚ÇÅ + (3/‚àö6)e‚ÇÇ = (2, 1, 1) = v

-------------------------------------------------------------------------------------
4) Matrix viewpoint
-------------------------------------------------------------------------------------
Matrix Q = [e‚ÇÅ e‚ÇÇ]

Then:
c = Q·µÄv
Projection onto the span: proj(v) = Q Q·µÄ v (reconsturction of V)

If Q is square and orthonormal, Q‚Åª¬π = Q·µÄ.

-------------------------------------------------------------------------------------
5) Orthogonal projection explained
-------------------------------------------------------------------------------------
Projection means finding the point v_S inside the subspace S = span{e‚ÇÅ, e‚ÇÇ, ‚Ä¶}
that is closest to v, such that v - v_S ‚üÇ S.

For orthonormal basis:
proj_S(v) = (v¬∑e‚ÇÅ)e‚ÇÅ + (v¬∑e‚ÇÇ)e‚ÇÇ + ‚Ä¶ = Q Q·µÄ v

Example (same as before):
v = (2,1,1)
c‚ÇÅ = 3/‚àö2, c‚ÇÇ = 3/‚àö6
proj_S(v) = c‚ÇÅ e‚ÇÅ + c‚ÇÇ e‚ÇÇ = (2,1,1)

Since v already lies in the span, projection equals v.

-------------------------------------------------------------------------------------
6) Matrix computation example for QQ·µÄv
-------------------------------------------------------------------------------------
Q =
[ 0.7071   0.4082 ]
[ 0.7071  -0.4082 ]
[ 0.0000   0.8165 ]

v = [2, 1, 1]^T

Step 1: Q·µÄv = [2.1213, 1.2247]^T

Step 2: Q(Q·µÄv) =
[ 0.7071  0.4082 ] [2.1213]
[ 0.7071 -0.4082 ] [1.2247]
[ 0.0000  0.8165 ]
= (2, 1, 1)

v lies entirely in the plane spanned by e‚ÇÅ and e‚ÇÇ.

-------------------------------------------------------------------------------------
7) Interpretation of coordinates c‚ÇÅ, c‚ÇÇ and relation to eigenvalues
-------------------------------------------------------------------------------------
- c·µ¢ = v¬∑e·µ¢ are the coordinate scalars ‚Äî they tell how much v points along each orthonormal direction.
- They are **not eigenvalues** by themselves.

Eigenvalues appear only when there is a linear operator A such that
A e·µ¢ = Œª·µ¢ e·µ¢.
Then, projecting v along each eigenvector ùëíùëñ gives the decomposition
of v in the eigenbasis.

c·µ¢ = v¬∑e·µ¢

A e·µ¢ = Œª·µ¢ e·µ¢.

Applying A to v scales each component c·µ¢ by the corresponding eigenvalue Œª·µ¢:

A v = Œ£ c·µ¢ Œª·µ¢ e·µ¢.

So eigenvalues describe how the operator scales eigenvectors,
while c·µ¢ describe how v is composed of those directions.


General proof: Why A v = Œ£_i c_i Œª_i e_i holds

Assume:
- A is a diagonalizable (or symmetric) linear operator on ‚Ñù^n.
- { e‚ÇÅ, e‚ÇÇ, ‚Ä¶, e‚Çô } are orthonormal eigenvectors of A.
- The corresponding eigenvalues are { Œª‚ÇÅ, Œª‚ÇÇ, ‚Ä¶, Œª‚Çô }, meaning A e·µ¢ = Œª·µ¢ e·µ¢ for all i.

Let any vector v ‚àà ‚Ñù‚Åø be expressed as a linear combination of these eigenvectors:
  v = Œ£_i c·µ¢ e·µ¢
where c·µ¢ = v ¬∑ e·µ¢ are the coordinates of v in the eigenbasis.

Goal: Prove that A v = Œ£_i c·µ¢ Œª·µ¢ e·µ¢.

Proof:
1) Start from the linearity of A:
   A(v) = A(Œ£_i c·µ¢ e·µ¢) = Œ£_i A(c·µ¢ e·µ¢)

2) Constants can be factored out of linear maps:
   Œ£_i A(c·µ¢ e·µ¢) = Œ£_i c·µ¢ A(e·µ¢)

3) Use the eigenvector property A e·µ¢ = Œª·µ¢ e·µ¢:
   Œ£_i c·µ¢ A(e·µ¢) = Œ£_i c·µ¢ (Œª·µ¢ e·µ¢)

4) Simplify notation:
   A v = Œ£_i c·µ¢ Œª·µ¢ e·µ¢

This completes the proof.

Interpretation:
- Each component of v in the eigenbasis (the c·µ¢)
 is scaled by its corresponding eigenvalue Œª·µ¢ when A acts on v.
- So A acts as a *diagonal operator* in the eigenbasis.

Matrix form equivalence:
Let Q = [ e‚ÇÅ e‚ÇÇ ... e‚Çô ] and Œõ = diag(Œª‚ÇÅ, ..., Œª‚Çô).

Then for any v:
  v = Q c  where  c = Q·µÄ v.
  A v = Q Œõ Q·µÄ v = Q Œõ c = Œ£_i Œª·µ¢ c·µ¢ e·µ¢.

Hence the identity holds both in vector and matrix form.

Geometric meaning:
A simply stretches or compresses v along each eigenvector direction e·µ¢ by factor Œª·µ¢.


Why A = Q Œõ Q·µÄ? 
Spectral decomposition (A = Q Œõ Q^T)
--------------------------------------
- Suppose A is a real symmetric matrix 
(or more generally diagonalizable with an orthonormal eigenbasis).
- Let e_1,...,e_n be orthonormal eigenvectors of A and 
Œª_1,...,Œª_n their eigenvalues, so A e_i = Œª_i e_i.
- Put the eigenvectors as columns of Q: Q = [ e_1 e_2 ... e_n ].
Then Q is orthogonal: Q^T Q = I.
- Let Œõ = diag(Œª_1,...,Œª_n). The eigen-equations for all columns
can be written together as: A Q = Q Œõ.
- Multiply on the right by Q^T and use Q Q^T = I to get:
A = Q Œõ Q^T.
This is the spectral (eigendecomposition) of A.

Interpretation: write A as: 
rotate to eigenbasis (Q^T), scale each coordinate by Œõ, rotate back (Q).

--
Coordinates in eigenbasis, and effect of A:

- Coordinates of a vector v in the eigenbasis are given by c = Q^T v. So v = Q c and c_i = v ¬∑ e_i.
- Apply A:
    A v = (Q Œõ Q^T) v = Q Œõ (Q^T v) = Q Œõ c.
- Œõ c = (Œª_1 c_1, Œª_2 c_2, ..., Œª_n c_n)^T.
- Therefore:
    A v = Q (Œõ c) = Œ£_i (Œª_i c_i) e_i.
  So, in the eigenbasis, coordinates are simply scaled: c'_i = Œª_i c_i.
  In other words, A multiplies the coefficient along each eigenvector e_i by the eigenvalue Œª_i.

Geometric intuition
- Q^T: change coordinates from standard basis to eigenbasis (express vector in eigen-directions).
- Œõ: scale each eigen-coordinate independently by Œª_i.
- Q: convert scaled coordinates back to the original coordinate system.
- So A acts by "rotate ‚Üí scale ‚Üí rotate back".


-------------------------------------------------------------------------------------
8) Summary formulas
-------------------------------------------------------------------------------------
Coordinates:   c = Q·µÄv
Projection:    v_proj = Q Q·µÄ v
Residual:      r = v - v_proj  (orthogonal to subspace)

If basis vectors are eigenvectors of a symmetric matrix A:
A v = Q Œõ Q·µÄ v = Œ£ Œª·µ¢ c·µ¢ e·µ¢


"""


"""
eigenvectors are not always normalized by default. 
An eigenvector v multiplied by any non-zero scalar c (i.e., cv) 
is still an eigenvector for the same eigenvalue. 
The length of an eigenvector is arbitrary by definition, 
although they can be scaled (normalized) to unit length for convenience.
¬†Furthermore, eigenvectors do not always form an orthonormal basis 
(a set of mutually orthogonal unit vectors) for the entire vector space.

This depends on the specific matrix:¬†

General Matrices: For most matrices, eigenvectors are neither necessarily
orthogonal nor do they always form a complete basis. 

Normal (e.g., Real Symmetric) Matrices: A special class of matrices called
normal matrices (which includes all real symmetric matrices) is guaranteed
to have a full set of eigenvectors that can be chosen to form an orthonormal
basis. For these matrices, eigenvectors corresponding to distinct eigenvalues
are automatically orthogonal.

In essence, while you can always normalize any given non-zero eigenvector to
unit length, the set of all eigenvectors for a general matrix may not be orthogonal
to each other, nor form a complete basis.¬†

"""