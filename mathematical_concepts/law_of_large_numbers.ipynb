{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "404397c6-5c29-44e9-a860-30a13c2e0b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# ! pip3 install scipy\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6feac6d6-d150-47c3-9869-e65b2ef5a63c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.78676866  1.33960941  0.86356562  1.61161539  1.86484455  0.90516332\n",
      "  1.21514956 -0.96340817 -1.06097487  2.59309748]\n"
     ]
    }
   ],
   "source": [
    "mean = 0\n",
    "std_dev = 1\n",
    "\n",
    "data = np.random.normal(mean, std_dev, 1000)\n",
    "\n",
    "print(data[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be11d4b3-a91e-43ae-bf6d-80aa1ce8a7c6",
   "metadata": {},
   "source": [
    "### Law of Large Numbers\n",
    "\n",
    "The **law of large numbers** is a fundamental theorem in probability theory. It states that if an experiment is repeated many times, the average of the observed outcomes tends to approach the expected value.\n",
    "\n",
    "Let:\n",
    "\n",
    "$$\n",
    "\\overline{X}_n = \\frac{X_1 + X_2 + \\dots + X_n}{n}\n",
    "$$\n",
    "\n",
    "be the sample mean based on observations $ X_1, X_2, \\dots, X_n $ drawn from a distribution with expected value $ \\mu $.\n",
    "\n",
    "---\n",
    "\n",
    "### Weak Law of Large Numbers\n",
    "\n",
    "If $ X_1, X_2, \\dots $ are independent and identically distributed (i.i.d.) random variables with a finite expectation $ \\mu $, then the sample mean $ \\overline{X}_n $ satisfies:\n",
    "\n",
    "$$\n",
    "\\lim_{n \\to \\infty} P(|\\overline{X}_n - \\mu| > \\epsilon) = 0\n",
    "$$\n",
    "\n",
    "This means that for large $ n $, the probability that the sample mean deviates from the expected value by more than any fixed $ \\epsilon > 0 $ becomes negligible.\n",
    "\n",
    "---\n",
    "\n",
    "### Strong Law of Large Numbers (SLLN)\n",
    "\n",
    "The **strong law** strengthens this result by stating that:\n",
    "\n",
    "$$\n",
    "\\lim_{n \\to \\infty} \\overline{X}_n = \\mu \\quad \\text{almost surely}\n",
    "$$\n",
    "\n",
    "Equivalently,\n",
    "\n",
    "$$\n",
    "P\\left( \\lim_{n \\to \\infty} \\overline{X}_n = \\mu \\right) = 1\n",
    "$$\n",
    "\n",
    "This guarantees that the sample mean converges to the true mean with probability one as the number of trials becomes large (in the long run).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81dd5e18-f780-416d-9236-e0ea630c8d18",
   "metadata": {},
   "source": [
    "### Empirical Distribution Function (EDF)\n",
    "\n",
    "The **Empirical Distribution Function (EDF)** is a statistical tool used to estimate the cumulative distribution function (CDF) of a given sample. It provides a non-parametric estimate of the distribution from which the sample was drawn.\n",
    "\n",
    "The EDF is defined as:\n",
    "\n",
    "$$\n",
    "F_n(x) = \\frac{\\text{number of elements in the dataset } \\leq x}{n}\n",
    "$$\n",
    "\n",
    "where $ n $ is the total number of observations.\n",
    "\n",
    "---\n",
    "\n",
    "In fact, there is a direct relationship between a histogram and the empirical distribution function. The area under a single bin of the histogram represents the relative frequency of the elements within that bin, which corresponds to the increase in $ F_n $ over that interval (on that bin).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7b1a09-4b97-4a19-b482-39a36c580e72",
   "metadata": {},
   "source": [
    "Given a sample of $ n $ independent and identically distributed (i.i.d.) random variables $ X_1, X_2, \\dots, X_n $, the **empirical distribution function** $ F_n(x) $ is defined as:\n",
    "\n",
    "$$\n",
    "F_n(x) = \\frac{1}{n} \\sum_{i=1}^n 1_{ X_i \\leq x}\n",
    "$$\n",
    "\n",
    "where $ 1_{ X_i \\leq x} $ is the indicator function that equals 1 if $ X_i \\leq x $ and 0 otherwise. The function $ F_n(x) $ represents the proportion of sample points less than or equal to $ x $.\n",
    "\n",
    "---\n",
    "\n",
    "### Properties of the Empirical Distribution Function\n",
    "\n",
    "- **Step Function**: The EDF is a step function that increases by $ \\frac{1}{n} $ at each sample point.\n",
    "- **Convergence**: As $ n \\to \\infty $, $ F_n(x) $ converges uniformly to the true cumulative distribution function $ F(x) $.\n",
    "- **Approximation**: For most realizations of the random sample, the empirical distribution function $ F_n(x) $ is close to the true distribution function $ F(x) $:\n",
    "\n",
    "  $$\n",
    "  F_n(a) \\approx F(a)\n",
    "  $$\n",
    "\n",
    "- **Law of Large Numbers**: The EDF satisfies the Law of Large Numbers, meaning it approaches the true distribution function as more data is collected.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee9cacfd-6c80-4824-b71f-2df98e6f49cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical distribution function value for 0: 0.506\n"
     ]
    }
   ],
   "source": [
    "def empirical_distribution_function(data, value):\n",
    "\n",
    "    sorted_data = np.sort(data)\n",
    "    \n",
    "    # Count the number of data points less than or equal to the given value\n",
    "    count = np.sum(sorted_data <= value)\n",
    "    \n",
    "    # Compute the EDF\n",
    "    edf = count / len(sorted_data)\n",
    "    \n",
    "    return edf\n",
    "\n",
    "\n",
    "data = np.random.normal(0, 1, 1000)  \n",
    "value = 0  # Example value\n",
    "edf_value = empirical_distribution_function(data, value)\n",
    "print(f\"Empirical distribution function value for {value}: {edf_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0576c5-54b6-4374-9526-580b4ed9ad3f",
   "metadata": {},
   "source": [
    "<h4>Identically distributed and Independent Random Variables</h4>\n",
    "Identically distributed: Each $X_i$ should come from the same underlying distribution.\n",
    "\n",
    "Independent: No sample value should influence another."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a553427-1651-4ed8-858b-c7088614014f",
   "metadata": {},
   "source": [
    "<h4>The Inverse Cumulative Distribution Function (CDF) </h4>\n",
    "\n",
    "The inverse cumulative distribution function (CDF) is a function that \"reverses\" the effect of the cumulative distribution function. Given a probability $ p $, it returns the value of the random variable such that the probability of the random variable being less than or equal to that value is $ p $.\n",
    "\n",
    "Mathematically, for a random variable $ X $ with cumulative distribution function $ F(x) $, the inverse CDF, denoted as $ F^{-1}(p) $, satisfies the condition:\n",
    "\n",
    "$$\n",
    "F^{-1}(p) = x \\quad \\text{if} \\quad F(x) = p\n",
    "$$\n",
    "\n",
    "In simpler terms, given a probability $ p $, the inverse CDF provides the value $ x $ such that $ F(x) = p $.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5b7a2d6-3255-449d-9d8c-f08a547d3639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CDF at 1.5: 0.9331927987311419\n",
      "CDF at 0: 0.5\n"
     ]
    }
   ],
   "source": [
    "def normal_cdf(x, mu, sigma):\n",
    "    # x: The value(s) at which to compute the CDF.\n",
    "    return norm.cdf(x, mu, sigma)\n",
    "\n",
    "\n",
    "mu = 0\n",
    "sigma = 1\n",
    "x = 1.5\n",
    "cdf_value = normal_cdf(x, mu, sigma)\n",
    "print(f\"CDF at {x}: {cdf_value}\")\n",
    "x = 0\n",
    "cdf_value = normal_cdf(x, mu, sigma)\n",
    "print(f\"CDF at {x}: {cdf_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8d3a29a-2a7b-4ff4-a226-3117e4f5113d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value corresponding to the probability 0.5: 0.0\n",
      "The value corresponding to the probability 0.9331927987311419: 1.4999999999999996\n"
     ]
    }
   ],
   "source": [
    "def inverse_normal_cdf(p, mu, sigma):\n",
    "    #  percent-point function (ppf) aka inverse CDF\n",
    "    return norm.ppf(p, mu, sigma)\n",
    "\n",
    "mu = 0\n",
    "sigma = 1\n",
    "p = 0.5\n",
    "x = inverse_normal_cdf(p, mu, sigma)\n",
    "print(f\"The value corresponding to the probability {p}: {x}\")\n",
    "p = 0.9331927987311419\n",
    "x = inverse_normal_cdf(p, mu, sigma)\n",
    "print(f\"The value corresponding to the probability {p}: {x}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93f5d4c-04c1-4880-a1b1-b5a1e49148ef",
   "metadata": {},
   "source": [
    "<h3>Non-Parametric Estimates</h3>\n",
    "\n",
    "In situations where we lack sufficient knowledge about the underlying phenomenon, it is often preferable not to assume a specific parametric form for the probability distribution. Instead, we treat the available dataset as a realization of a random sample of size $ N $ drawn from an unknown continuous probability distribution.\n",
    "\n",
    "To approximate the true probability density function $ f $ and the cumulative distribution function $ F $, we use the kernel density estimate and the empirical distribution function, respectively. By examining the resulting plots of these estimates, we may gain insights into whether the underlying distribution resembles any known parametric distribution.\n",
    "\n",
    "Rather than interpreting these two plots solely as graphical summaries of the data, we can also treat them as estimators for the true functions. Specifically, the kernel density estimate serves as an estimator for the density function $ f $, while the empirical distribution function estimates the cumulative distribution function $ F $.\n",
    "\n",
    "Because these approaches do not assume any particular parametric model, they are referred to as non-parametric estimates.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
